{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c41f75a4-c06f-48c7-a256-4ec6131aebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from rdkit import Chem\n",
    "# from rdkit.Chem import Descriptors, Lipinski\n",
    "# from chembl_webresource_client.new_client import new_client\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6fa8208-0294-4cca-9e65-c82f2f34a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_bioactivity_data(target_entry):\n",
    "#     target_id = target_entry['target_chembl_id']\n",
    "    \n",
    "#     # Get bioactivity data for the target\n",
    "#     bioactivities = activity.filter(\n",
    "#         target_chembl_id=target_id,\n",
    "#         type='MIC'\n",
    "#     ).only(\n",
    "#         'molecule_chembl_id', \n",
    "#         'canonical_smiles',  \n",
    "#         'standard_value',\n",
    "#         'standard_units',\n",
    "#         'standard_type',\n",
    "#         'pchembl_value',\n",
    "#         'target_pref_name',\n",
    "#         'bao_label'\n",
    "#     )\n",
    "#     df_bioactivities = pd.DataFrame(bioactivities)\n",
    "#     df_bioactivities = df_bioactivities.drop_duplicates(subset=['canonical_smiles'])\n",
    "    \n",
    "#     if not df_bioactivities.empty:\n",
    "#         df_bioactivities['passes_lipinski'] = df_bioactivities['canonical_smiles'].apply(check_lipinski_rule)\n",
    "#         df_bioactivities = df_bioactivities[df_bioactivities['passes_lipinski']]\n",
    "#         df_bioactivities['standard_value'] = pd.to_numeric(df_bioactivities['standard_value'], errors='coerce')\n",
    "#         df_bioactivities = df_bioactivities.dropna(subset=['standard_value'])\n",
    "#         df_bioactivities = df_bioactivities[[\n",
    "#             'molecule_chembl_id', \n",
    "#             'canonical_smiles',  \n",
    "#             'standard_value',\n",
    "#             'standard_units',\n",
    "#             'standard_type',\n",
    "#             'pchembl_value',\n",
    "#             'target_pref_name',\n",
    "#             'bao_label', \n",
    "#             'passes_lipinski'\n",
    "#         ]]\n",
    "#         print(f\"Processed {len(df_bioactivities)} entries for target {target_id}\")\n",
    "#         return df_bioactivities\n",
    "#     else:\n",
    "#         print(f\"No valid data for target {target_id}\")\n",
    "#         return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e5a88a7-e9cf-445c-a56b-aee0b9d70ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     target = new_client.target\n",
    "#     activity = new_client.activity\n",
    "#     target_query = target.search('bacteria')\n",
    "#     targets = target_query.all()\n",
    "\n",
    "#     output_folder = 'Bacteria_Dataset (forreal)'\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#     test_bioactivities_list = []\n",
    "\n",
    "#     with ProcessPoolExecutor() as executor:\n",
    "#         results = list(executor.map(fetch_bioactivity_data, targets))\n",
    "\n",
    "#     # Concatenate all DataFrames outside the loop\n",
    "#     test_bioactivities_list = pd.concat(results, ignore_index=True)\n",
    "\n",
    "#     csv_filename = os.path.join(output_folder, 'Bacteria_MICsss.csv')\n",
    "#     test_bioactivities_list.to_csv(csv_filename, index=False)\n",
    "#     print(len(test_bioactivities_list))\n",
    "#     print(\"Done :D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c17e0447-43d2-44c2-b32d-33d1be568e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tanimoto Similarity: 0.07407407407407407\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.DataStructs import TanimotoSimilarity\n",
    "\n",
    "def calculate_tanimoto_similarity(molecule1, molecule2):\n",
    "    if molecule1 is None or molecule2 is None:\n",
    "        return None\n",
    "\n",
    "    # Generate Morgan fingerprints\n",
    "    fp1 = AllChem.GetMorganFingerprintAsBitVect(molecule1, 2, nBits=2048)\n",
    "    fp2 = AllChem.GetMorganFingerprintAsBitVect(molecule2, 2, nBits=2048)\n",
    "\n",
    "\n",
    "    similarity = TanimotoSimilarity(fp1, fp2)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "mol1 = Chem.MolFromSmiles(\"CCC[C@@H]1C[C@@H](C(=O)N[C@@H]([C@H]2O[C@H](SC)[C@H](O)[C@@H](O)[C@H]2O)[C@H](C)Cl)N(C)C1\")\n",
    "mol2 = Chem.MolFromSmiles(\"C/C(O)=C(\\C#N)C(=O)Nc1ccc(C(F)(F)F)cc1\")\n",
    "\n",
    "similarity_score = calculate_tanimoto_similarity(mol1, mol2)\n",
    "\n",
    "if similarity_score is not None:\n",
    "    print(f\"Tanimoto Similarity: {similarity_score}\")\n",
    "else:\n",
    "    print(\"Invalid SMILES string. Unable to calculate similarity.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a103ee5-9c28-437e-b9bf-0cd7deaf6c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c20446a-3e6a-439a-ab56-ef1f0f31649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLATING THE COLLECTED DATA INTO A CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75960396-3127-4da1-b3a2-1d8b5ba08631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'Antibiotic_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Antifungal_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Antihelminthic_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Antiparasitic_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Antiviral_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Bacteria_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Cryptosporidium_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Entamoeba_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Fungi_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Giardia_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Leishmania_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Nematoda_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Plasmodium_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Schistosoma_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Toxoplasma_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Trachomatis_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Trypanosoma_IC50.csv' collected from 'None_RO5'.\n",
      "File 'Virus_IC50.csv' collected from 'None_RO5'.\n",
      "CSV files collected successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def collect_csv_files(source_folders, destination_folder):\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Loop through selected source folders\n",
    "    for source_folder in source_folders:\n",
    "        # Check if the source folder exists\n",
    "        if not os.path.exists(source_folder):\n",
    "            print(f\"Warning: Folder '{source_folder}' not found. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Iterate through files in the source folder\n",
    "        for filename in os.listdir(source_folder):\n",
    "            file_path = os.path.join(source_folder, filename)\n",
    "\n",
    "            # Check if it's a CSV file\n",
    "            if filename.lower().endswith('.csv') and os.path.isfile(file_path):\n",
    "                # Copy the CSV file to the destination folder\n",
    "                shutil.copy(file_path, destination_folder)\n",
    "                print(f\"File '{filename}' collected from '{source_folder}'.\")\n",
    "\n",
    "# List of folders to collect CSV files from\n",
    "selected_folders = [\n",
    "    'None_RO5'\n",
    "]\n",
    "# Destination folder\n",
    "destination_folder = 'Combined_None_RO5'\n",
    "\n",
    "# Collect CSV files\n",
    "collect_csv_files(selected_folders, destination_folder)\n",
    "\n",
    "print(\"CSV files collected successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28f888a1-5804-4e64-972a-bd480659d22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files combined and duplicates removed. Result saved to 'Combined_None_RO5\\_None_RO5_Dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "all_csv_files = pd.concat([pd.read_csv(os.path.join(destination_folder, file)) for file in os.listdir(destination_folder) if file.lower().endswith('.csv')])\n",
    "\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "result_file_path = os.path.join(destination_folder, '_None_RO5_Dataset.csv')\n",
    "all_csv_files.to_csv(result_file_path, index=False)\n",
    "\n",
    "print(f\"CSV files combined and duplicates removed. Result saved to '{result_file_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d5195b57-4a45-463c-87e8-6e2b831a991a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file processed successfully. Result saved to '_Dataset_for_GANs.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "input_file = '_None_RO5_Dataset.csv'  # Replace with the actual file path\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Convert 'standard_value' to numeric\n",
    "df['standard_value'] = pd.to_numeric(df['standard_value'], errors='coerce')\n",
    "\n",
    "# Drop duplicates based on 'canonical_smiles' and keep the first occurrence\n",
    "result_df = df.drop_duplicates('canonical_smiles', keep='first')\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "output_file = '_Dataset_for_GANs.csv'  # Replace with the desired output file path\n",
    "result_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"CSV file processed successfully. Result saved to '{output_file}'.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716a7013-eb21-401c-9a08-9a4455264b67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
